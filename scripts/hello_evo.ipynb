{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izYUNEppoX58"
      },
      "source": [
        "# 🧬 + 🤖 **Hello Evo**: From DNA generation to protein folding\n",
        "\n",
        "\n",
        "Evo is a 7B long-context biological foundation model that generalizes across the fundamental languages of biology: DNA, RNA, and proteins. It is capable of both prediction tasks and generative design, from molecular to whole genome scale (generating over 650k tokens). We trained Evo at a single-nucleotide (byte) resolution, on a large corpus of prokaryotic and phage sequences covering 2.7 million genomes.\n",
        "\n",
        "Evo is based on the [StripedHyena](https://www.together.ai/blog/stripedhyena-7b) architecture to enable modeling of sequences at byte-level resolution with near-linear scaling of compute and memory relative to context length.\n",
        "\n",
        "Learn more about Evo here:\n",
        "- 📄 [Preprint](https://www.biorxiv.org/content/10.1101/2024.02.27.582234v1)\n",
        "- 🌐 [Blog](https://arcinstitute.org/news/blog/evo)\n",
        "- 💽 [GitHub](https://github.com/evo-design/evo)\n",
        "- 🎨 [Generate DNA in the Browser](https://api.together.xyz/playground/language/togethercomputer/evo-1-131k-base)\n",
        "- 🤗 [Checkpoint](https://huggingface.co/togethercomputer/evo-1-131k-base)\n",
        "\n",
        "\n",
        "## 👉 Before you start:\n",
        "We will use the [Together AI API](https://docs.together.ai/docs/quickstart) to generate DNA with Evo.\n",
        "To run this colab, you will thus need to set up an account with Together AI:\n",
        "[www.together.ai](https://www.together.ai/).\n",
        "Don't worry, you will get some free compute credits when signing up!\n",
        "\n",
        "🖖 If you don't want to sign up, we also provide a script demonstrating the process from DNA generation to protein folding using our model checkpoints hosted on HuggingFace and only local hardware: [github.com/evo-design/evo/scripts/generation_to_folding.py](https://github.com/evo-design/evo/blob/main/scripts/generation_to_folding.py)\n",
        "\n",
        "*This colab was created by [Armin Thomas](https://athms.me) in Feb. `24.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N7-2BWANd96U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mina practice\n"
      ],
      "metadata": {
        "id": "orhMoESWeBFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "cna0QNAbeFhF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX0F2adA9j8P"
      },
      "source": [
        "# 1. Installs and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pBbWoZmZ4ncF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b8a26c-0b77-462a-9b90-1e004b35a651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✨🍰✨ Everything looks OK!\n",
            "Channels:\n",
            " - bioconda\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.3\n",
            "    latest version: 25.5.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Before we begin, we need to install prodigal, which we will use later\n",
        "# to predict protein-coding genes from our generated DNA sequences.\n",
        "# We install prodigal through conda, which might take a few minutes...\n",
        "!pip install -q condacolab # -> condacolab allows us to install with conda\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!conda install -c bioconda prodigal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gi7qnLwa1xVK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91008de4-db83-4ce8-8a09-70e29d2c380f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: together in /usr/local/lib/python3.11/site-packages (1.5.13)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/site-packages (1.7.0)\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.11/site-packages (1.85)\n",
            "Requirement already satisfied: biotite in /usr/local/lib/python3.11/site-packages (1.3.0)\n",
            "Requirement already satisfied: py3Dmol in /usr/local/lib/python3.11/site-packages (2.5.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.11/site-packages (from together) (3.12.13)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/site-packages (from together) (8.1.8)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.11/site-packages (from together) (0.2.2)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.11/site-packages (from together) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/site-packages (from together) (2.3.0)\n",
            "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /usr/local/lib/python3.11/site-packages (from together) (11.2.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/site-packages (from together) (2.11.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/site-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.8.1 in /usr/local/lib/python3.11/site-packages (from together) (14.0.0)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/site-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.11/site-packages (from together) (4.67.1)\n",
            "Requirement already satisfied: typer<0.16,>=0.9 in /usr/local/lib/python3.11/site-packages (from together) (0.15.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/site-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/site-packages (from accelerate) (2.7.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/site-packages (from accelerate) (0.33.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/site-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: biotraj<2.0,>=1.0 in /usr/local/lib/python3.11/site-packages (from biotite) (1.2.2)\n",
            "Requirement already satisfied: msgpack>=0.5.6 in /usr/local/lib/python3.11/site-packages (from biotite) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.11/site-packages (from biotite) (3.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.20.1)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.11/site-packages (from biotraj<2.0,>=1.0->biotite) (1.15.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.5.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (1.1.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.6.3->together) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.6.3->together) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->together) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->together) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->together) (2025.6.15)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/site-packages (from rich<15.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/site-packages (from rich<15.0.0,>=13.8.1->together) (2.19.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.3.1)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/site-packages (from triton==3.3.1->torch>=2.0.0->accelerate) (65.6.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/site-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.8.1->together) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# We also need to install a few more python dependencies:\n",
        "# ...this might also take a few minutes...\n",
        "!pip install together accelerate biopython biotite py3Dmol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nxooR1LM2Umv"
      },
      "outputs": [],
      "source": [
        "# Ok, we are ready to begin and import all tools we will use in this colab:\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import py3Dmol # -> used to visualize protein structures\n",
        "import together # -> to call the API\n",
        "# ↓ Tools to process DNA and protein data\n",
        "import biotite.structure.io as bsio\n",
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "# ↓ To load ESMFold from HuggingFace, which we use to predict protein foldings\n",
        "from transformers import (\n",
        "  AutoTokenizer,\n",
        "  EsmForProteinFolding,\n",
        "  set_seed\n",
        ")\n",
        "\n",
        "# Let's also enable TensorFloat32 computation for some speedups:\n",
        "torch.backends.cuda.matmul.allow_tf32 = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFS6p4_EopVr"
      },
      "source": [
        "# 2. Setting up the API and your prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jWMftPgo0n6Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "21a06fac-8e1f-416c-f9c5-ece0e0fe0e4e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Please provide a Together API key.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-4213167452>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# You can find your API key under Settings -> API keys @www.together.ai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mTOGETHER_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;31m# <- insert your key here!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTOGETHER_API_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Please provide a Together API key.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 2. Key arguments for generating DNA with Evo:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Please provide a Together API key."
          ]
        }
      ],
      "source": [
        "# We begin by setting some key variables for our code:\n",
        "\n",
        "# 1. Together API key:\n",
        "# You can find your API key under Settings -> API keys @www.together.ai\n",
        "TOGETHER_API_KEY = '' # <- insert your key here!\n",
        "assert len(TOGETHER_API_KEY)>0, 'Please provide a Together API key.'\n",
        "\n",
        "# 2. Key arguments for generating DNA with Evo:\n",
        "evo_name = 'togethercomputer/evo-1-131k-base' # -> base model with 131k context\n",
        "# the model with 8k context is called by: 'togethercomputer/evo-1-8k-base'\n",
        "\n",
        "# Our prompting scheme follows \"Greengenes-style lineage strings\",\n",
        "# which concatenate all taxa starting with the most ancestral and ending\n",
        "# with the most current, separated by semicolons. A single character\n",
        "# prefix is also added to each taxon indicating its rank.\n",
        "# For more information, see:\n",
        "# https://github.com/qiyunzhu/woltka/blob/main/doc/hierarchy.md#3-lineage-strings---lineage\n",
        "prompt = (\n",
        "  \"|\" # -> start prompt\n",
        "  +\"d__Bacteria;\"\n",
        "  +\"p__Pseudomonadota;\"\n",
        "  +\"c__Gammaproteobacteria;\"\n",
        "  +\"o__Enterobacterales;\"\n",
        "  +\"f__Enterobacteriaceae;\"\n",
        "  +\"g__Escherichia;\"\n",
        "  +\"s__Escherichia\"\n",
        "  +\"|\" # -> end prompt\n",
        ")\n",
        "# ...so cool that we can use natural language-like prompts for Evo!!\n",
        "# ----\n",
        "# /!\\ IMPORTANT:\n",
        "# The 8k context model does not allow for this kind of prompting scheme!\n",
        "# It can, however, be used to predict continuations for DNA sequences\n",
        "# that you provide as input.\n",
        "# ----\n",
        "\n",
        "# ↓ A few more variables to control the generation process\n",
        "max_tokens = 1024 # we want to generate maximally 1024 new tokens\n",
        "temperature = 1. # The sampling temperature (between 0 and 2) controls\n",
        "# the randomness with which the model picks tokens during generation.\n",
        "# Higher values (eg, >1) will make the generations more diverse (-> more random).\n",
        "# Lower values (eg, <1) will make them less diverse (-> more deterministic).\n",
        "top_k = 4 # Specifies the maximum number of tokens to be considered at each\n",
        "# generation step, based on their probability of occurrence.\n",
        "# This can help speed up the generation process and improve\n",
        "# the quality of the generated tokens by focusing on the most likely options.\n",
        "top_p = 1. # As an alternative to the sampling temperature, we can also set\n",
        "# the \"top_p\" parameter. The model only considers the those tokens for\n",
        "# generation that contain the top_p probability mass.\n",
        "# Eg, with top_p = 0.1, the model only considers the tokens comprising\n",
        "# the top 10% probability -> leading to generally less diverse generations.\n",
        "# When top_p = 1, all tokens are considered -> more diverse generations.\n",
        "\n",
        "# ~ We generally recommend to set temperature = top_p = 1 and top_k = 4 ~\n",
        "\n",
        "# 3. Paths to local files that we will generate:\n",
        "sequence_fasta = './sequence.fasta'\n",
        "proteins_fasta = './proteins.fasta'\n",
        "protein_structure_pdb = './protein_structure.pdb'\n",
        "# Learn more about the .fasta format here:\n",
        "# https://en.wikipedia.org/wiki/FASTA_format\n",
        "\n",
        "# 4. Misc arguments:\n",
        "device = 'cuda'\n",
        "seed = 123456789"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "dk_CDiPehfqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run 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\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "wUAERqiihhBk",
        "outputId": "55336ff1-d7cb-4d71-e816-b33c315c7475"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "File `'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.py'` not found.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/utils/path.py\u001b[0m in \u001b[0;36mget_py_filename\u001b[0;34m(name, force_win32)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'File `%r` not found.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: File `'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.py'` not found.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1874617960>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'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'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-52>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nt'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"^'.*'$\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                 \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'For Windows, use double quotes to wrap a filename: %run \"mypath\\\\myfile.py\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: File `'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.py'` not found."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePA4UIU59Va-"
      },
      "outputs": [],
      "source": [
        "# We try our best to make this code reproducible:\n",
        "torch.manual_seed(seed) # pytorch random seed\n",
        "set_seed(seed) # huggingface random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUsmRrpr9Rq6"
      },
      "outputs": [],
      "source": [
        "# These are some additional prompt examples for the 131k model:\n",
        "\n",
        "# prompt2 = \"|d__Bacteria;p__Tenericutes;c__Mollicutes;o__Mycoplasmatales;f__Mycoplasmataceae;g__Mycoplasma;s__Mycoplasma genitalium|\"\n",
        "# prompt3 = \"|d__Bacteria;p__Bacillota;c__Bacilli;o__Staphylococcales;f__Staphylococcaceae;g__Staphylococcus;s__Staphylococcus aureus|\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh6CWnOIn5x1"
      },
      "source": [
        "# 3. Calling the Together API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8quVgSQw5_F"
      },
      "outputs": [],
      "source": [
        "# We are now ready to generate DNA with Evo, using the Together API.\n",
        "# To call the API, we will use the together python package:\n",
        "\n",
        "# 1. Make your API key accessible to the together library:\n",
        "together.api_key = TOGETHER_API_KEY\n",
        "\n",
        "# 2. Specify the message to be sent to Evo:\n",
        "output = together.Complete.create(\n",
        "  prompt = prompt,\n",
        "  model = evo_name,\n",
        "  # ↓ our generation paramaters\n",
        "  max_tokens = max_tokens,\n",
        "  temperature = temperature,\n",
        "  top_k = top_k,\n",
        "  top_p = top_p,\n",
        "  logprobs = True # lets also collect the log probs for the generated tokens\n",
        ")\n",
        "# ----\n",
        "# /!\\ IMPORTANT:\n",
        "# Please note that we currently cannot set a random seed\n",
        "# when prompting the Together API. For this reason, we also\n",
        "# cannot guarantee reproducible results.\n",
        "# ----\n",
        "\n",
        "# Learn more about the together python library here:\n",
        "# https://docs.together.ai/docs/inference-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45Dedu4F0VSC"
      },
      "outputs": [],
      "source": [
        "# This is how Evo's generated DNA sequence looks like:\n",
        "gen_dna_seq = output['choices'][0]['text']\n",
        "print('Generated DNA sequence: ',gen_dna_seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uIzGCK7oEDM"
      },
      "source": [
        "# 4. Analyzing the generated DNA sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cE_LjPRQk28"
      },
      "outputs": [],
      "source": [
        "# We can also take a peak at the log probabilities for each generated token:\n",
        "\n",
        "# 1. Extract probabilities:\n",
        "gen_dna_logprobs = output['choices'][0]['logprobs']['token_logprobs']\n",
        "gen_dna_probs = np.exp(gen_dna_logprobs)\n",
        "\n",
        "# 2. Compute exponential moving average over probabilities (for plotting):\n",
        "def exponential_moving_average(x, alpha: float=0.1):\n",
        "  \"\"\"little helper to compute exponential moving average over input array x\"\"\"\n",
        "  ema = [x[0]]\n",
        "  for i in range(1, len(x)):\n",
        "      ema_value = alpha * x[i] + (1 - alpha) * ema[i - 1]\n",
        "      ema.append(ema_value)\n",
        "  return np.array(ema)\n",
        "\n",
        "ema_gen_dna_probs = exponential_moving_average(gen_dna_probs)\n",
        "\n",
        "# 3. Plot probabilities & EMA:\n",
        "fig, ax = plt.subplots(1,1,figsize=(24,3))\n",
        "ax.bar(np.arange(gen_dna_probs.shape[0]), gen_dna_probs, color='C0')\n",
        "ax.plot(ema_gen_dna_probs, color='C1', label='EMA')\n",
        "ax.set_xlabel('Token position')\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xlim(0, max_tokens)\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9h4jbij3gU_"
      },
      "outputs": [],
      "source": [
        "# We save the generated DNA sequence to a local .fasta file.\n",
        "# This will make it easier to digest for prodigal (see below).\n",
        "gen_dna_seq_record = SeqRecord(\n",
        "  Seq(gen_dna_seq),\n",
        "  id=\"evo-dna\",\n",
        "  description=\"DNA sequence generated by Evo.\"\n",
        ")\n",
        "with open(sequence_fasta, \"w\") as output_handle:\n",
        "  SeqIO.write(gen_dna_seq_record, output_handle, \"fasta\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4t4K7X3biMt"
      },
      "outputs": [],
      "source": [
        "# This is how the sequence_fasta file looks like:\n",
        "!cat '{sequence_fasta}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd5dzNPb-lKX"
      },
      "source": [
        "# 5. Predicting protein-coding genes from the DNA sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDGzM4sB3kcT"
      },
      "outputs": [],
      "source": [
        "# To predict protein-coding genes from our DNA sequence, we use prodigal.\n",
        "# We run prodigal as a shell command, using the sequence_fasta as input,\n",
        "# and saving the results to another fasta file (-> proteins_fasta):\n",
        "!prodigal -i '{sequence_fasta}' -a '{proteins_fasta}' -o 'genes.gff' -p 'meta' -f 'gff'\n",
        "\n",
        "# Learn more about prodigal here: https://github.com/hyattpd/prodigal/wiki"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOQyzU2Dczl5"
      },
      "outputs": [],
      "source": [
        "# This is how our saved proteins_fasta file looks like:\n",
        "!cat '{proteins_fasta}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlIAjNPXxzn0"
      },
      "outputs": [],
      "source": [
        "# Let's also see where these predicted protein-coding genes\n",
        "# lie on our generated DNA sequence:\n",
        "\n",
        "# 1. Read protein-coding gene coordinates from the .fasta file:\n",
        "def load_fasta(file_path):\n",
        "  \"\"\"a little helper to load records from a .fasta file\"\"\"\n",
        "  sequences = []\n",
        "  with open(file_path, \"r\") as handle:\n",
        "      for record in SeqIO.parse(handle, \"fasta\"):\n",
        "          sequences.append(record)\n",
        "  return sequences\n",
        "\n",
        "def extract_start_end_coords(sequences):\n",
        "  \"\"\"a little helper to extract the start and\n",
        "  end coordinates of the predicted protein-coding\n",
        "  genes\"\"\"\n",
        "  coordinates = []\n",
        "  for record in sequences:\n",
        "      start, end = map(int, [info.strip() for info in record.description.split('#')[1:3]])\n",
        "      coordinates.append((start, end))\n",
        "  return coordinates\n",
        "\n",
        "gene_seqs = load_fasta(proteins_fasta)\n",
        "gene_coords = extract_start_end_coords(gene_seqs)\n",
        "\n",
        "# 2. Add coordinates to our previous token probability plot:\n",
        "fig, ax = plt.subplots(1,1,figsize=(24,3))\n",
        "ax.bar(np.arange(gen_dna_probs.shape[0]), gen_dna_probs, color='C0')\n",
        "ax.plot(ema_gen_dna_probs, color='C1', label='EMA')\n",
        "for ci, coords in enumerate(gene_coords):\n",
        "   ax.fill_between(\n",
        "    coords,\n",
        "    -.1, 0,\n",
        "    color=f'C{4+ci}',\n",
        "    alpha=0.75,\n",
        "    edgecolor='k',\n",
        "    linewidth=2,\n",
        "    label=f'coding region {ci+1}',\n",
        "    zorder=-99\n",
        "  )\n",
        "ax.set_xlabel('Token position')\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xlim(0, max_tokens)\n",
        "ax.set_ylim(-0.15, 1)\n",
        "ax.legend(frameon=True, loc='upper center', ncols=2, fontsize='large')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft72BHu2oNcr"
      },
      "source": [
        "# 6. Predicting protein structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CUmw4GL4Z7T"
      },
      "outputs": [],
      "source": [
        "# To fold our predicted protein-coding genes, we use ESMFold,\n",
        "# as recently published by Meta:\n",
        "# https://www.science.org/doi/abs/10.1126/science.ade2574\n",
        "\n",
        "# Luckily, ESMFold is hosted on HuggingFace,\n",
        "# so loading and using the model is a breeze:\n",
        "# ~ Open source for the win! ~\n",
        "esmfold = EsmForProteinFolding.from_pretrained(\n",
        "  \"facebook/esmfold_v1\",\n",
        "  low_cpu_mem_usage = True # we set this flag to save some RAM during loading\n",
        ")\n",
        "esmfold = esmfold.to(device) # -> move ESMFold to the GPU\n",
        "esmfold.esm = esmfold.esm.half() # -> make sure we use a lightweight precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgxVkTfY5NuI"
      },
      "outputs": [],
      "source": [
        "# We will also need the ESMFold tokenizer to map our predicted protein-coding\n",
        "# genes to the token vocabulary of ESMFold:\n",
        "esmfold_tokenizer = AutoTokenizer.from_pretrained(\"facebook/esmfold_v1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzA0gRlj4cdi"
      },
      "outputs": [],
      "source": [
        "# Using ESMFold, we can easily predict a protein folding structure:\n",
        "\n",
        "# 1. Select a predicted protein-coding gene that we want to fold:\n",
        "i = 0 # lets just use the first one.\n",
        "protein_record = list(SeqIO.parse(proteins_fasta, \"fasta\"))[i]\n",
        "protein_seq = str(protein_record.seq)[:-1] # remove stop codon\n",
        "\n",
        "# 2. Tokenize the gene to make it digestible for ESMFold:\n",
        "esmfold_in = esmfold_tokenizer(\n",
        "  [protein_seq],\n",
        "  return_tensors=\"pt\",\n",
        "  add_special_tokens=False\n",
        ")\n",
        "\n",
        "# 3. Feed the tokenized sequence to ESMfold:\n",
        "# (in PyTorch's inference_mode to avoid any costly gradient computations)\n",
        "with torch.inference_mode():\n",
        "  esmfold_out = esmfold(**esmfold_in.to(device))\n",
        "  esmfold_out_pdb = esmfold.output_to_pdb(esmfold_out)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5AmMjMAdmWo"
      },
      "outputs": [],
      "source": [
        "# This is how our predicted protein structure looks like in numbers:\n",
        "with open(protein_structure_pdb, \"w\") as f:\n",
        "  f.write(esmfold_out_pdb)\n",
        "\n",
        "protein_structure = bsio.load_structure(\n",
        "  protein_structure_pdb,\n",
        "  extra_fields=[\"b_factor\"]\n",
        ")\n",
        "print('Generated protein structure: ', protein_structure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7-QGydxdbCj"
      },
      "outputs": [],
      "source": [
        "# ...but it's much nicer to look at as a graphic :-)\n",
        "view = py3Dmol.view(\n",
        "  js='https://3dmol.org/build/3Dmol.js',\n",
        "  width=800,\n",
        "  height=400\n",
        ")\n",
        "view.addModel(\"\".join(esmfold_out_pdb), 'pdb')\n",
        "view.setStyle({'model': -1}, {\"cartoon\": {'color': 'spectrum'}})\n",
        "view.zoomTo()\n",
        "view.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc_toEuNo73I"
      },
      "source": [
        "# 🍭 Stay tuned!\n",
        "\n",
        "We are planning to open source more Evo models over time, including finetuned models for creating CRISPR systems and mobile genetic elements.\n",
        "\n",
        "An important part of the Evo generation pipeline is to screen/filter for high quality samples. We utilize a number of existing (and amazing!) tools for this, like [Prodigal](https://github.com/hyattpd/Prodigal), [CheckM](https://ecogenomics.github.io/CheckM/), and [BLAST](https://blast.ncbi.nlm.nih.gov/Blast.cgi). Going forward, we plan to incorporate these more into our public codebase and modeling pipelines, hoping to provide useful and openly available tools for the community. We are looking forward to this journey and invite you to join us!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69b0b4e5"
      },
      "source": [
        "!pip install transformers==4.28.1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}